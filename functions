import cv2 
import numpy as np 
import scipy as sp
import scipy.ndimage
import json
import os.path

class LicensePlateDetector:
    def __init__(self, pth_weights: str, pth_cfg: str, pth_classes: str):
        self.net = cv2.dnn.readNet(pth_weights, pth_cfg)
        self.classes = []
        with open(pth_classes, 'r') as f:
            self.classes = f.read().splitlines()
        self.font = cv2.FONT_HERSHEY_PLAIN
        self.color = (255, 0, 0)
        self.coordinates = None
        self.img = None
        self.fig_image = None
        self.roi_image = None

    def detect(self, img_path: str):
        orig = cv2.imread(img_path)
        self.img = orig
        img = orig.copy()
        height, width, _ = img.shape
        blob = cv2.dnn.blobFromImage(img, 1 / 255, (416, 416), (0, 0, 0), swapRB=True, crop=False)
        self.net.setInput(blob)
        output_layer_names = self.net.getUnconnectedOutLayersNames()
        layer_outputs = self.net.forward(output_layer_names)
        boxes = []
        confidences = []
        class_ids = []

        for output in layer_outputs:
            for detection in output:
                scores = detection[5:]
                class_id = np.argmax(scores) 
                confidence = scores[class_id]
                if confidence > 0.2:
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)
                    x = int(center_x - w / 2)
                    y = int(center_y - h / 2)

                    boxes.append([x, y, w, h])
                    confidences.append((float(confidence)))
                    class_ids.append(class_id)

        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)

        if len(indexes) > 0:
            for i in indexes.flatten():
                x, y, w, h = boxes[i]
                label = str(self.classes[class_ids[i]])
                confidence = str(round(confidences[i],2))
                cv2.rectangle(img, (x,y), (x + w, y + h), self.color, 10)
                cv2.putText(img, label + ' ' + confidence, (x-30, y + 10), self.font, 2, (0, 255, 0), 3)
        self.fig_image = img
        self.coordinates = (x, y, w, h)
        return 
    
    def crop_plate(self):
        x, y, w, h = self.coordinates
        roi = self.img[y:y + h, x:x + w]
        self.roi_image = roi
        return x, y, w, h, roi

    
class Functions:
    def flood_fill(test_array, h_max=255):
        input_array = np.copy(test_array)
        el = sp.ndimage.generate_binary_structure(2, 2).astype(int)
        inside_mask = sp.ndimage.binary_erosion(
            ~np.isnan(input_array), structure=el)
        output_array = np.copy(input_array)
        output_array[inside_mask] = h_max
        output_old_array = np.copy(input_array)
        output_old_array.fill(0)
        el = sp.ndimage.generate_binary_structure(2, 1).astype(int)
        while not np.array_equal(output_old_array, output_array):
            output_old_array = np.copy(output_array)
            output_array = np.maximum(input_array, sp.ndimage.grey_erosion(output_array,
            size=(3, 3)))
        return output_array
    
    def threshholding(image):
        Lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)
        blurred = cv2.GaussianBlur(Lab, (7, 7), 0)
        (L, a, b) = cv2.split(blurred)
        number = np.median(L[L > 0])
        return number
    
    
class Color:
    def rgb_to_hsv(r, g, b):
        r, g, b = r / 255.0, g / 255.0, b / 255.0
        cmax = max(r, g, b)
        cmin = min(r, g, b)
        diff = cmax-cmin
        if cmax == cmin:
            h = 0
        elif cmax == r:
            h = (60 * ((g - b) / diff) + 360) % 360
        elif cmax == g:
            h = (60 * ((b - r) / diff) + 120) % 360
    
        elif cmax == b:
            h = (60 * ((r - g) / diff) + 240) % 360
        if cmax == 0:
            s = 0
        else:
            s = (diff / cmax) * 100
        v = cmax * 100
        hsv = [ h, s, v]
        return hsv
    
    def run_grabcut(img_orig, rect_final):
        mask = np.zeros(img_orig.shape[:2],np.uint8) 
        x,y,w,h = rect_final 
        mask[y:y+h, x:x+w] = 1 
        bgdModel = np.zeros((1,65), np.float64) 
        fgdModel = np.zeros((1,65), np.float64) 
        # Run Grabcut algorithm 
        cv2.grabCut(img_orig, mask, rect_final, bgdModel, fgdModel, 3, cv2.GC_INIT_WITH_RECT) 
        mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8') 
        img_origG = img_orig*mask2[:,:,np.newaxis] 
        # cv2.imshow('Output', img_origG) 
        return img_origG

def add_json(plate, brand, color):
    if os.path.isfile('data.txt'):
        with open('data.txt') as json_file:
            data = json.load(json_file)
    else:
        data = {}
        data['car'] = []
        with open('data.txt', 'w') as outfile:
            json.dump(data, outfile)
    
    data['car'].append({
    'plate': plate,
    'brandImage': brand,
    'color': color
    })
    
    with open('data.txt', 'w') as outfile:
        json.dump(data, outfile)
    # print("\nAdded to the File: [License Plate: %s | Brand: %s | Color: %s] " % (plate, brand, color))
    print("\nAdded to the File: [License Plate: %s | BrandImage: %s | Color: %s] " % (plate, brand, color))



